{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name and Surname: CUONG VO\\\n",
    "Student ID: 131116\n",
    "\n",
    "Using CUDA for GPU processing (on Linux OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Approach:\n",
    "1. Create multiple block of convolutional with multiple kernel size \n",
    "2. Apply Batch nomalization\n",
    "3. Decrease of learning rate to 0.0001\n",
    "4. Reduce batch size to 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the accuracy of a Convolutional Neural Network (CNN), several techniques can be applied effectively. Batch normalization was utilized to stabilize and accelerate training by normalizing the inputs to each layer, reducing internal covariate shifts. Additionally, dropout was introduced as a regularization method to prevent overfitting by randomly deactivating neurons during training, which promotes robustness in the model. Finally, the learning rate was decreased to ensure the optimizer converges more smoothly to the global minimum, avoiding overshooting and improving the model's generalization on unseen data. These combined strategies can enhance CNN performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To balance the trade-off between computational efficiency and predictive performance, I decided to set the learning rate to 0.0001 and the batch size to 16. The lower learning rate ensures a stable and gradual convergence to the optimal solution, improving the model's ability to generalize. Meanwhile, the smaller batch size reduces memory usage and allows for more frequent updates to the model, which can help capture finer patterns in the data despite slightly longer training times. This approach provided a good balance, leading to improved accuracy without excessive computational demands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Impletementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, ParameterSchedulers, Optimisers, Statistics, CUDA \n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON, JLD2, LinearAlgebra\n",
    "using ImageCore, Images\n",
    "using MLDatasets: convert2image, FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset FashionMNIST:\n",
       "  metadata  =>    Dict{String, Any} with 4 entries\n",
       "  split     =>    :train\n",
       "  features  =>    28×28×60000 Array{Float32, 3}\n",
       "  targets   =>    60000-element Vector{Int64}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = FashionMNIST(:train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA61JREFUaAW9wc2LlAUcAODnnfc3s+vurIamuJK4C7XVoTDS0BIhyXtYFHSJwEvQrf+gQKJOHbp1Cbp7EKyIOlqkkKigUAqyurT5sbvlzozzmfAGshCxG/F7npAsJAvJQrKQLCQLyUKykCwkC8lCsrBBBUYqUziEr1QKlOhbq1AZISQLyUKysEE1DPA4jqONVXTwE/oqBWoo0FcpEZKFZCFZ2KASAxzBK7iBMUzgKD7HIkYYqDQxRAshWUgWkoUN6qrsxwxK1PANnsPHOIeLuIwXsB9n8ANCspAsJAsbUGCEo9iHPzGJOczhLH5FEy/iGHo4i+PoIiQLyUKysA6FtT7EtMoE+ujiEPZhiJ/xC/p4D7N4HSFZSBaShXUYWWsJ02hjDHU00cEmDHEIB1HDDnytEpKFZCFZ+A8mUKKGFlZwFzMYokANExhgiN0qIVlIFpKFdShQwwBN7EIHXTTQxSq24A4m0MA9bMYFNLEPIVlIFpKFdRihxABvYhq/YxxDTGI3uhhDD4FxbMNn2ItASBaShWRhHQJdlUvooIEahtiBDu6gjnFMYgk38BY+wY8IyUKykCz8rUCJGgr0MFTpe+g0VtFGAyPcQolx9FR6GKLEs1hRCclCspAsPFBigL5/dhiv4SW0cQcNBAZoocQYxjFCS6WBVRzDKYRkIVlIFh4YeGgrdmEO0ziGJ9FBDavYhgV00MAOdDGBM2jiMIZYQRcHVEKykCwkCw8cxAfYjkcwQIll9PEHuijQxhm8gXOYwn3MqDyDKcyjhU1oYo9KSBaShWRR4lPsQh8DtFQaGKCtsgV78BHaeBcL6OA7XMMT2IYu6qihj1sqIVlIFpLF29iDq2iiia0qdWzBPBYwgUV8gVdxCrOYxPN4GTV0MYaGSh917EZIFpKFZLGIeWxGB/NoooHNuIvraKKNDvo4iYuYwVZ0sYweBuiijiEKNDCHkCwkC8niJkaYxyQexTJu4xYCY6hjHFOo4TaexirmsYQx3EYPffSwCTuxgr0IyUKykCzO4yTewQKuoYMmGhhHAyXuY4ARWvgNQwwQ6KCJLpaxjB76mMUiQrKQLCQLD5zAebyPWdzCMlZRooFAiQIj1FHHOOooVAosoomtGGInLuBLhGQhWUgWNQxxGqdxBCewB1tQQ4nAAAUWMcJN3Mc9lCoj9NBCDd/iMs6ohGQhWUgWQ2t9jwMqT2E7lvAYrqOLq/67kCwkC8nCv7iCKyqX/D9CspAsJAvJQrKQLCT7C6Vm6Bx367f0AAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA61JREFUaAW9wc2LlAUcAODnnfc3s+vurIamuJK4C7XVoTDS0BIhyXtYFHSJwEvQrf+gQKJOHbp1Cbp7EKyIOlqkkKigUAqyurT5sbvlzozzmfAGshCxG/F7npAsJAvJQrKQLCQLyUKykCwkC8lCsrBBBUYqUziEr1QKlOhbq1AZISQLyUKysEE1DPA4jqONVXTwE/oqBWoo0FcpEZKFZCFZ2KASAxzBK7iBMUzgKD7HIkYYqDQxRAshWUgWkoUN6qrsxwxK1PANnsPHOIeLuIwXsB9n8ANCspAsJAsbUGCEo9iHPzGJOczhLH5FEy/iGHo4i+PoIiQLyUKysA6FtT7EtMoE+ujiEPZhiJ/xC/p4D7N4HSFZSBaShXUYWWsJ02hjDHU00cEmDHEIB1HDDnytEpKFZCFZ+A8mUKKGFlZwFzMYokANExhgiN0qIVlIFpKFdShQwwBN7EIHXTTQxSq24A4m0MA9bMYFNLEPIVlIFpKFdRihxABvYhq/YxxDTGI3uhhDD4FxbMNn2ItASBaShWRhHQJdlUvooIEahtiBDu6gjnFMYgk38BY+wY8IyUKykCz8rUCJGgr0MFTpe+g0VtFGAyPcQolx9FR6GKLEs1hRCclCspAsPFBigL5/dhiv4SW0cQcNBAZoocQYxjFCS6WBVRzDKYRkIVlIFh4YeGgrdmEO0ziGJ9FBDavYhgV00MAOdDGBM2jiMIZYQRcHVEKykCwkCw8cxAfYjkcwQIll9PEHuijQxhm8gXOYwn3MqDyDKcyjhU1oYo9KSBaShWRR4lPsQh8DtFQaGKCtsgV78BHaeBcL6OA7XMMT2IYu6qihj1sqIVlIFpLF29iDq2iiia0qdWzBPBYwgUV8gVdxCrOYxPN4GTV0MYaGSh917EZIFpKFZLGIeWxGB/NoooHNuIvraKKNDvo4iYuYwVZ0sYweBuiijiEKNDCHkCwkC8niJkaYxyQexTJu4xYCY6hjHFOo4TaexirmsYQx3EYPffSwCTuxgr0IyUKykCzO4yTewQKuoYMmGhhHAyXuY4ARWvgNQwwQ6KCJLpaxjB76mMUiQrKQLCQLD5zAebyPWdzCMlZRooFAiQIj1FHHOOooVAosoomtGGInLuBLhGQhWUgWNQxxGqdxBCewB1tQQ4nAAAUWMcJN3Mc9lCoj9NBCDd/iMs6ohGQhWUgWQ2t9jwMqT2E7lvAYrqOLq/67kCwkC8nCv7iCKyqX/D9CspAsJAvJQrKQLCT7C6Vm6Bx367f0AAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{Float32},2} with eltype Gray{Float32}:\n",
       " Gray{Float32}(0.0)         …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0117647)\n",
       " Gray{Float32}(0.0)         …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0588235)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.258824)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " ⋮                          ⋱  \n",
       " Gray{Float32}(0.384314)       Gray{Float32}(0.113725)\n",
       " Gray{Float32}(0.294118)    …  Gray{Float32}(0.262745)\n",
       " Gray{Float32}(0.188235)       Gray{Float32}(0.45098)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.360784)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.00784314)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)         …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert2image(FashionMNIST, train_set.features)[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using package CUDA and CuDNN for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on GPU\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X12sdnNjb2RlLXJlbW90ZQ==.jl:4\n"
     ]
    }
   ],
   "source": [
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize for epochs and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150;\n",
    "batch_size = 16;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_minibatch (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X)[1], size(X)[2], 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, 1, i] = Float32.(X[:, :, idxs[i]])\n",
    "    end\n",
    "    Y_batch = Flux.onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750-element Vector{Tuple{CuArray{Float32, 4, CUDA.DeviceMemory}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.DeviceMemory}}}}:\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 1 0 … 0 1])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[1 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.003921569 0.0 … 0.003921569 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[1 0 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 0 0 … 0 1])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 1 … 0 0; … ; 0 0 … 1 0; 0 0 … 0 1])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 1 … 0 1; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 1 0 … 0 0; 0 0 … 0 0])\n",
       " ⋮\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 1; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.003921569 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 1; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 1 0; 0 0 … 0 0; … ; 0 0 … 0 0; 1 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.003921569 … 0.0 0.0; 0.0 0.003921569 … 0.0 0.03529412; … ; 0.0 0.0 … 0.015686275 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 1; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.007843138 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 1 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mb_idxs = partition(1:size(train_set.features)[3], batch_size)\n",
    "train_set = [make_minibatch(train_set.features, train_set.targets, i) for i in mb_idxs] |> device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 1 0 … 0 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set = FashionMNIST(:test)\n",
    "test_set = make_minibatch(test_set.features, test_set.targets, 1:size(test_set.features)[3]) |> device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> OLD MODEL </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 128),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ") |> device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> IMPROVED MODEL </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 1 => 32, relu, pad=1),   \u001b[90m# 320 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Conv((3, 3), 32 => 32, relu, pad=1),  \u001b[90m# 9_248 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Conv((5, 5), 32 => 32, relu, pad=2, stride=2),  \u001b[90m# 25_632 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Conv((3, 3), 32 => 64, relu, pad=1),  \u001b[90m# 18_496 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Conv((3, 3), 64 => 64, relu, pad=1),  \u001b[90m# 36_928 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Conv((5, 5), 64 => 64, relu, pad=2, stride=2),  \u001b[90m# 102_464 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Conv((3, 3), 64 => 128, relu, pad=1),  \u001b[90m# 73_856 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Conv((3, 3), 128 => 128, relu, pad=1),  \u001b[90m# 147_584 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Conv((5, 5), 128 => 128, relu, pad=2, stride=2),  \u001b[90m# 409_728 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  var\"#13#14\"(),\n",
       "  Dense(2048 => 512, relu),             \u001b[90m# 1_049_088 parameters\u001b[39m\n",
       "  BatchNorm(512),                       \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Dense(512 => 128, relu),              \u001b[90m# 65_664 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Dense(128 => 10),                     \u001b[90m# 1_290 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m        # Total: 46 trainable arrays, \u001b[39m1_942_922 parameters,\n",
       "\u001b[90m          # plus 22 non-trainable, 2_624 parameters, summarysize \u001b[39m11.367 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>32, pad=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    Conv((3, 3), 32=>32, pad=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    Conv((5, 5), 32=>32, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(32),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv((3, 3), 32=>64, pad=(1, 1), relu),\n",
    "    BatchNorm(64),\n",
    "    Conv((3, 3), 64=>64, pad=(1, 1), relu),\n",
    "    BatchNorm(64),\n",
    "    Conv((5, 5), 64=>64, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(64),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv((3, 3), 64=>128, pad=(1, 1), relu),\n",
    "    BatchNorm(128),\n",
    "    Conv((3, 3), 128=>128, pad=(1, 1), relu),\n",
    "    BatchNorm(128),\n",
    "    Conv((5, 5), 128=>128, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(128),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(2048, 512, relu),\n",
    "    BatchNorm(512),\n",
    "    Dropout(0.4),\n",
    "    Dense(512, 128, relu),\n",
    "    BatchNorm(128),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ") |> device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×16 CuArray{Float32, 2, CUDA.DeviceMemory}:\n",
       " 0.100139   0.100138   0.100056   …  0.100019   0.100095   0.100107\n",
       " 0.100047   0.0999982  0.100067      0.100055   0.100021   0.100059\n",
       " 0.0999461  0.0999641  0.0999688     0.0999542  0.0999132  0.099937\n",
       " 0.100061   0.0999617  0.100001      0.0999652  0.0999856  0.100067\n",
       " 0.100147   0.100112   0.10007       0.100058   0.100051   0.100188\n",
       " 0.100002   0.100001   0.100014   …  0.0999995  0.0999585  0.0999647\n",
       " 0.0998687  0.0999438  0.0999141     0.0999353  0.0999654  0.0998312\n",
       " 0.0999349  0.0999427  0.0999624     0.10005    0.100007   0.100037\n",
       " 0.0999343  0.100039   0.0999959     0.100024   0.100024   0.0998951\n",
       " 0.0999203  0.0998994  0.0999519     0.0999385  0.0999789  0.0999141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(train_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loss(model, x, y, device = device)\n",
    "    x = x |>cpu\n",
    "    x_aug = x .+ 0.1f0*randn(eltype(x), size(x)) |> device\n",
    "    y_hat = model(x_aug)\n",
    "    return Flux.crossentropy(y_hat, y) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.790224 seconds (9.02 M allocations: 462.183 MiB, 1.54% gc time, 70.45% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1285"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(model, test_set[1],test_set[2])\n",
    "accuracy(model,x, y) = mean(Flux.onecold(model(x)) .== Flux.onecold(y))\n",
    "@time accuracy(model,test_set[1],test_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterSchedulers.Stateful{Exp{Float64}, Int64, ParameterSchedulers.var\"#15#17\"}(Exp{Float64}(1.0e-5, 0.1), 1, ParameterSchedulers.var\"#15#17\"())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = Flux.Adam(0.0001)\n",
    "opt_state = Flux.setup(opt, model);\n",
    "lr_schedule = ParameterSchedulers.Stateful(Exp(start = opt.eta/10, decay = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:1\n",
      "┌ Info: [1]: Test accuracy: 0.7726\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [2]: Test accuracy: 0.8381\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [3]: Test accuracy: 0.8645\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [4]: Test accuracy: 0.8727\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [5]: Test accuracy: 0.8857\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [6]: Test accuracy: 0.8862\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [7]: Test accuracy: 0.8911\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [8]: Test accuracy: 0.8989\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [9]: Test accuracy: 0.8959\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [10]: Test accuracy: 0.9031\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [11]: Test accuracy: 0.9021\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [12]: Test accuracy: 0.9044\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [13]: Test accuracy: 0.9062\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [14]: Test accuracy: 0.9076\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [15]: Test accuracy: 0.9081\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [16]: Test accuracy: 0.9122\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [17]: Test accuracy: 0.9116\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [18]: Test accuracy: 0.9118\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [19]: Test accuracy: 0.9083\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [20]: Test accuracy: 0.9102\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [21]: Test accuracy: 0.9137\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [22]: Test accuracy: 0.9130\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [23]: Test accuracy: 0.9178\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [24]: Test accuracy: 0.9157\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [25]: Test accuracy: 0.9114\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [26]: Test accuracy: 0.9192\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [27]: Test accuracy: 0.9155\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [28]: Test accuracy: 0.9197\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [29]: Test accuracy: 0.9182\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [30]: Test accuracy: 0.9184\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [31]: Test accuracy: 0.9137\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [32]: Test accuracy: 0.9124\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [33]: Test accuracy: 0.9206\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [34]: Test accuracy: 0.9159\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [35]: Test accuracy: 0.9152\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [36]: Test accuracy: 0.9180\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [37]: Test accuracy: 0.9146\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [38]: Test accuracy: 0.9191\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [39]: Test accuracy: 0.9180\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [40]: Test accuracy: 0.9168\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [41]: Test accuracy: 0.9190\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [42]: Test accuracy: 0.9204\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [43]: Test accuracy: 0.9174\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [44]: Test accuracy: 0.9212\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [45]: Test accuracy: 0.9209\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [46]: Test accuracy: 0.9188\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [47]: Test accuracy: 0.9207\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [48]: Test accuracy: 0.9187\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [49]: Test accuracy: 0.9189\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [50]: Test accuracy: 0.9219\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [51]: Test accuracy: 0.9191\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [52]: Test accuracy: 0.9215\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [53]: Test accuracy: 0.9248\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [54]: Test accuracy: 0.9233\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [55]: Test accuracy: 0.9218\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [56]: Test accuracy: 0.9198\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [57]: Test accuracy: 0.9228\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [58]: Test accuracy: 0.9177\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000004e-8!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [59]: Test accuracy: 0.9205\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [60]: Test accuracy: 0.9227\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [61]: Test accuracy: 0.9204\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [62]: Test accuracy: 0.9202\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [63]: Test accuracy: 0.9220\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000003e-9!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [64]: Test accuracy: 0.9188\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [65]: Test accuracy: 0.9232\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [66]: Test accuracy: 0.9139\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [67]: Test accuracy: 0.9201\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [68]: Test accuracy: 0.9238\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000003e-10!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [69]: Test accuracy: 0.9205\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [70]: Test accuracy: 0.9169\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [71]: Test accuracy: 0.9227\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [72]: Test accuracy: 0.9241\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [73]: Test accuracy: 0.9200\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [74]: Test accuracy: 0.9225\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [75]: Test accuracy: 0.9194\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [76]: Test accuracy: 0.9200\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [77]: Test accuracy: 0.9213\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [78]: Test accuracy: 0.9219\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> We're calling this converged.\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/Final_report/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sdnNjb2RlLXJlbW90ZQ==.jl:30\n"
     ]
    }
   ],
   "source": [
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch = 1:epochs\n",
    "    global best_acc, last_improvement\n",
    "    Flux.train!(loss, model, train_set, opt_state)\n",
    "    acc = accuracy(model,test_set[1],test_set[2])\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch, acc))\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to fashionMNIST_conv.bson\")\n",
    "        ps = cpu(Flux.state(model))\n",
    "        BSON.@save \"fashionMNIST_conv.bson\" ps\n",
    "        jldsave(\"fashionMNIST_conv.jld2\"; ps)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if acc >= 0.95\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 95%\")\n",
    "        break\n",
    "    end\n",
    "    if epoch - last_improvement >= 5 \n",
    "        η = ParameterSchedulers.next!(lr_schedule) \n",
    "        if η ≥ 1e-10\n",
    "            Optimisers.adjust(opt_state, eta = η)\n",
    "            @warn(\" -> Haven't improved in a while, dropping learning rate to $(η)!\")\n",
    "            last_improvement = epoch\n",
    "        end\n",
    "    end\n",
    "    if epoch - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By implementing batch normalization, dropout, and reducing the learning rate, I was able to improve the accuracy of my Convolutional Neural Network (CNN) from 90% to 92.32%. Batch normalization stabilized and accelerated the training process, while dropout reduced overfitting by encouraging the network to generalize better. Adjusting the learning rate helped the optimizer converge more effectively, allowing the model to learn finer details in the data. These enhancements collectively contributed to the notable accuracy improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 1 => 32, relu, pad=1),   \u001b[90m# 320 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Conv((3, 3), 32 => 32, relu, pad=1),  \u001b[90m# 9_248 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Conv((5, 5), 32 => 32, relu, pad=2, stride=2),  \u001b[90m# 25_632 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Conv((3, 3), 32 => 64, relu, pad=1),  \u001b[90m# 18_496 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Conv((3, 3), 64 => 64, relu, pad=1),  \u001b[90m# 36_928 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Conv((5, 5), 64 => 64, relu, pad=2, stride=2),  \u001b[90m# 102_464 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Conv((3, 3), 64 => 128, relu, pad=1),  \u001b[90m# 73_856 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Conv((3, 3), 128 => 128, relu, pad=1),  \u001b[90m# 147_584 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Conv((5, 5), 128 => 128, relu, pad=2, stride=2),  \u001b[90m# 409_728 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  var\"#15#16\"(),\n",
       "  Dense(2048 => 512, relu),             \u001b[90m# 1_049_088 parameters\u001b[39m\n",
       "  BatchNorm(512),                       \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Dense(512 => 128, relu),              \u001b[90m# 65_664 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Dense(128 => 10),                     \u001b[90m# 1_290 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m        # Total: 46 trainable arrays, \u001b[39m1_942_922 parameters,\n",
       "\u001b[90m          # plus 22 non-trainable, 2_624 parameters, summarysize \u001b[39m11.367 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isfile(\"fashionMNIST_conv.bson\") ||\n",
    "download(\"https://github.com/bartoszpankratz/221660-0553-Aproksymacja/blob/master/5.%20Sieci%20konwolucyjne/fashionMNIST_conv.bson?raw=true\")\n",
    "\n",
    "model = Chain(\n",
    "    Conv((3, 3), 1=>32, pad=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    Conv((3, 3), 32=>32, pad=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    Conv((5, 5), 32=>32, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(32),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv((3, 3), 32=>64, pad=(1, 1), relu),\n",
    "    BatchNorm(64),\n",
    "    Conv((3, 3), 64=>64, pad=(1, 1), relu),\n",
    "    BatchNorm(64),\n",
    "    Conv((5, 5), 64=>64, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(64),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv((3, 3), 64=>128, pad=(1, 1), relu),\n",
    "    BatchNorm(128),\n",
    "    Conv((3, 3), 128=>128, pad=(1, 1), relu),\n",
    "    BatchNorm(128),\n",
    "    Conv((5, 5), 128=>128, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(128),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(2048, 512, relu),\n",
    "    BatchNorm(512),\n",
    "    Dropout(0.4),\n",
    "    Dense(512, 128, relu),\n",
    "    BatchNorm(128),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ") |> device\n",
    "\n",
    "BSON.@load \"fashionMNIST_conv.bson\" ps\n",
    "\n",
    "Flux.loadmodel!(model, device(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy(model,test_set[1],test_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 1 => 32, relu, pad=1),   \u001b[90m# 320 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Conv((3, 3), 32 => 32, relu, pad=1),  \u001b[90m# 9_248 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Conv((5, 5), 32 => 32, relu, pad=2, stride=2),  \u001b[90m# 25_632 parameters\u001b[39m\n",
       "  BatchNorm(32),                        \u001b[90m# 64 parameters\u001b[39m\u001b[90m, plus 64\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Conv((3, 3), 32 => 64, relu, pad=1),  \u001b[90m# 18_496 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Conv((3, 3), 64 => 64, relu, pad=1),  \u001b[90m# 36_928 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Conv((5, 5), 64 => 64, relu, pad=2, stride=2),  \u001b[90m# 102_464 parameters\u001b[39m\n",
       "  BatchNorm(64),                        \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Conv((3, 3), 64 => 128, relu, pad=1),  \u001b[90m# 73_856 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Conv((3, 3), 128 => 128, relu, pad=1),  \u001b[90m# 147_584 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Conv((5, 5), 128 => 128, relu, pad=2, stride=2),  \u001b[90m# 409_728 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  var\"#17#18\"(),\n",
       "  Dense(2048 => 512, relu),             \u001b[90m# 1_049_088 parameters\u001b[39m\n",
       "  BatchNorm(512),                       \u001b[90m# 1_024 parameters\u001b[39m\u001b[90m, plus 1_024\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Dense(512 => 128, relu),              \u001b[90m# 65_664 parameters\u001b[39m\n",
       "  BatchNorm(128),                       \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  Dropout(0.4),\n",
       "  Dense(128 => 10),                     \u001b[90m# 1_290 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m        # Total: 46 trainable arrays, \u001b[39m1_942_922 parameters,\n",
       "\u001b[90m          # plus 22 non-trainable, 2_624 parameters, summarysize \u001b[39m11.367 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isfile(\"fashionMNIST_conv.jld2\") ||\n",
    "download(\"https://github.com/bartoszpankratz/221660-0553-Aproksymacja/blob/master/5.%20Sieci%20konwolucyjne/fashionMNIST_conv.jld2?raw=true\")\n",
    "\n",
    "model = Chain(\n",
    "    Conv((3, 3), 1=>32, pad=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    Conv((3, 3), 32=>32, pad=(1, 1), relu),\n",
    "    BatchNorm(32),\n",
    "    Conv((5, 5), 32=>32, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(32),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv((3, 3), 32=>64, pad=(1, 1), relu),\n",
    "    BatchNorm(64),\n",
    "    Conv((3, 3), 64=>64, pad=(1, 1), relu),\n",
    "    BatchNorm(64),\n",
    "    Conv((5, 5), 64=>64, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(64),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv((3, 3), 64=>128, pad=(1, 1), relu),\n",
    "    BatchNorm(128),\n",
    "    Conv((3, 3), 128=>128, pad=(1, 1), relu),\n",
    "    BatchNorm(128),\n",
    "    Conv((5, 5), 128=>128, stride=(2, 2), pad=(2, 2), relu),\n",
    "    BatchNorm(128),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(2048, 512, relu),\n",
    "    BatchNorm(512),\n",
    "    Dropout(0.4),\n",
    "    Dense(512, 128, relu),\n",
    "    BatchNorm(128),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ") |> device\n",
    "\n",
    "\n",
    "ps = JLD2.load(\"fashionMNIST_conv.jld2\", \"ps\")\n",
    "\n",
    "Flux.loadmodel!(model, device(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy(model,test_set[1],test_set[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
