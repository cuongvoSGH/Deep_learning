{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, ParameterSchedulers, Optimisers, Statistics, CUDA \n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON, JLD2, LinearAlgebra\n",
    "using ImageCore, Images\n",
    "using MLDatasets: convert2image, FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset FashionMNIST:\n",
       "  metadata  =>    Dict{String, Any} with 4 entries\n",
       "  split     =>    :train\n",
       "  features  =>    28×28×60000 Array{Float32, 3}\n",
       "  targets   =>    60000-element Vector{Int64}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = FashionMNIST(:train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA61JREFUaAW9wc2LlAUcAODnnfc3s+vurIamuJK4C7XVoTDS0BIhyXtYFHSJwEvQrf+gQKJOHbp1Cbp7EKyIOlqkkKigUAqyurT5sbvlzozzmfAGshCxG/F7npAsJAvJQrKQLCQLyUKykCwkC8lCsrBBBUYqUziEr1QKlOhbq1AZISQLyUKysEE1DPA4jqONVXTwE/oqBWoo0FcpEZKFZCFZ2KASAxzBK7iBMUzgKD7HIkYYqDQxRAshWUgWkoUN6qrsxwxK1PANnsPHOIeLuIwXsB9n8ANCspAsJAsbUGCEo9iHPzGJOczhLH5FEy/iGHo4i+PoIiQLyUKysA6FtT7EtMoE+ujiEPZhiJ/xC/p4D7N4HSFZSBaShXUYWWsJ02hjDHU00cEmDHEIB1HDDnytEpKFZCFZ+A8mUKKGFlZwFzMYokANExhgiN0qIVlIFpKFdShQwwBN7EIHXTTQxSq24A4m0MA9bMYFNLEPIVlIFpKFdRihxABvYhq/YxxDTGI3uhhDD4FxbMNn2ItASBaShWRhHQJdlUvooIEahtiBDu6gjnFMYgk38BY+wY8IyUKykCz8rUCJGgr0MFTpe+g0VtFGAyPcQolx9FR6GKLEs1hRCclCspAsPFBigL5/dhiv4SW0cQcNBAZoocQYxjFCS6WBVRzDKYRkIVlIFh4YeGgrdmEO0ziGJ9FBDavYhgV00MAOdDGBM2jiMIZYQRcHVEKykCwkCw8cxAfYjkcwQIll9PEHuijQxhm8gXOYwn3MqDyDKcyjhU1oYo9KSBaShWRR4lPsQh8DtFQaGKCtsgV78BHaeBcL6OA7XMMT2IYu6qihj1sqIVlIFpLF29iDq2iiia0qdWzBPBYwgUV8gVdxCrOYxPN4GTV0MYaGSh917EZIFpKFZLGIeWxGB/NoooHNuIvraKKNDvo4iYuYwVZ0sYweBuiijiEKNDCHkCwkC8niJkaYxyQexTJu4xYCY6hjHFOo4TaexirmsYQx3EYPffSwCTuxgr0IyUKykCzO4yTewQKuoYMmGhhHAyXuY4ARWvgNQwwQ6KCJLpaxjB76mMUiQrKQLCQLD5zAebyPWdzCMlZRooFAiQIj1FHHOOooVAosoomtGGInLuBLhGQhWUgWNQxxGqdxBCewB1tQQ4nAAAUWMcJN3Mc9lCoj9NBCDd/iMs6ohGQhWUgWQ2t9jwMqT2E7lvAYrqOLq/67kCwkC8nCv7iCKyqX/D9CspAsJAvJQrKQLCT7C6Vm6Bx367f0AAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA61JREFUaAW9wc2LlAUcAODnnfc3s+vurIamuJK4C7XVoTDS0BIhyXtYFHSJwEvQrf+gQKJOHbp1Cbp7EKyIOlqkkKigUAqyurT5sbvlzozzmfAGshCxG/F7npAsJAvJQrKQLCQLyUKykCwkC8lCsrBBBUYqUziEr1QKlOhbq1AZISQLyUKysEE1DPA4jqONVXTwE/oqBWoo0FcpEZKFZCFZ2KASAxzBK7iBMUzgKD7HIkYYqDQxRAshWUgWkoUN6qrsxwxK1PANnsPHOIeLuIwXsB9n8ANCspAsJAsbUGCEo9iHPzGJOczhLH5FEy/iGHo4i+PoIiQLyUKysA6FtT7EtMoE+ujiEPZhiJ/xC/p4D7N4HSFZSBaShXUYWWsJ02hjDHU00cEmDHEIB1HDDnytEpKFZCFZ+A8mUKKGFlZwFzMYokANExhgiN0qIVlIFpKFdShQwwBN7EIHXTTQxSq24A4m0MA9bMYFNLEPIVlIFpKFdRihxABvYhq/YxxDTGI3uhhDD4FxbMNn2ItASBaShWRhHQJdlUvooIEahtiBDu6gjnFMYgk38BY+wY8IyUKykCz8rUCJGgr0MFTpe+g0VtFGAyPcQolx9FR6GKLEs1hRCclCspAsPFBigL5/dhiv4SW0cQcNBAZoocQYxjFCS6WBVRzDKYRkIVlIFh4YeGgrdmEO0ziGJ9FBDavYhgV00MAOdDGBM2jiMIZYQRcHVEKykCwkCw8cxAfYjkcwQIll9PEHuijQxhm8gXOYwn3MqDyDKcyjhU1oYo9KSBaShWRR4lPsQh8DtFQaGKCtsgV78BHaeBcL6OA7XMMT2IYu6qihj1sqIVlIFpLF29iDq2iiia0qdWzBPBYwgUV8gVdxCrOYxPN4GTV0MYaGSh917EZIFpKFZLGIeWxGB/NoooHNuIvraKKNDvo4iYuYwVZ0sYweBuiijiEKNDCHkCwkC8niJkaYxyQexTJu4xYCY6hjHFOo4TaexirmsYQx3EYPffSwCTuxgr0IyUKykCzO4yTewQKuoYMmGhhHAyXuY4ARWvgNQwwQ6KCJLpaxjB76mMUiQrKQLCQLD5zAebyPWdzCMlZRooFAiQIj1FHHOOooVAosoomtGGInLuBLhGQhWUgWNQxxGqdxBCewB1tQQ4nAAAUWMcJN3Mc9lCoj9NBCDd/iMs6ohGQhWUgWQ2t9jwMqT2E7lvAYrqOLq/67kCwkC8nCv7iCKyqX/D9CspAsJAvJQrKQLCT7C6Vm6Bx367f0AAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{Float32},2} with eltype Gray{Float32}:\n",
       " Gray{Float32}(0.0)         …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0117647)\n",
       " Gray{Float32}(0.0)         …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0588235)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.258824)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " ⋮                          ⋱  \n",
       " Gray{Float32}(0.384314)       Gray{Float32}(0.113725)\n",
       " Gray{Float32}(0.294118)    …  Gray{Float32}(0.262745)\n",
       " Gray{Float32}(0.188235)       Gray{Float32}(0.45098)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.360784)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.00784314)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)         …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)            Gray{Float32}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert2image(FashionMNIST, train_set.features)[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on GPU\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W3sdnNjb2RlLXJlbW90ZQ==.jl:4\n"
     ]
    }
   ],
   "source": [
    "use_cuda = true\n",
    "if use_cuda && CUDA.functional()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150;\n",
    "batch_size = 64;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_minibatch (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X)[1], size(X)[2], 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, 1, i] = Float32.(X[:, :, idxs[i]])\n",
    "    end\n",
    "    Y_batch = Flux.onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938-element Vector{Tuple{CuArray{Float32, 4, CUDA.DeviceMemory}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.DeviceMemory}}}}:\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 1 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[1 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 1; 0 1 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 1 … 1 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 1; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 1 … 0 0; … ; 0 0 … 1 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[1 0 … 0 0; 0 0 … 0 1; … ; 0 0 … 0 0; 0 0 … 1 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 1 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 1; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])\n",
       " ⋮\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.011764706 0.0 … 0.9764706 0.20392157; 0.003921569 0.0 … 0.5294118 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 1; 0 0 … 0 0; … ; 0 0 … 0 0; 1 0 … 1 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 1])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 1])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 1 0 … 0 0; … ; 0 0 … 1 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 1])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 1 0; 1 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[1 0 … 0 0; 0 0 … 0 0; … ; 0 1 … 0 0; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.003921569 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 1; 0 0 … 0 0])\n",
       " ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 1 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mb_idxs = partition(1:size(train_set.features)[3], batch_size)\n",
    "train_set = [make_minibatch(train_set.features, train_set.targets, i) for i in mb_idxs] |> device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 1 0 … 0 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set = FashionMNIST(:test)\n",
    "test_set = make_minibatch(test_set.features, test_set.targets, 1:size(test_set.features)[3]) |> device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 1 => 16, relu, pad=1),   \u001b[90m# 160 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Conv((3, 3), 16 => 32, relu, pad=1),  \u001b[90m# 4_640 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Conv((3, 3), 32 => 32, relu, pad=1),  \u001b[90m# 9_248 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  var\"#13#14\"(),\n",
       "  Dense(288 => 128),                    \u001b[90m# 36_992 parameters\u001b[39m\n",
       "  Dense(128 => 10),                     \u001b[90m# 1_290 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 10 arrays, \u001b[39m52_330 parameters, 1.961 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 128),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ") |> device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×64 CuArray{Float32, 2, CUDA.DeviceMemory}:\n",
       " 0.132105   0.128793   0.11353    …  0.120433   0.114458   0.109565\n",
       " 0.116719   0.10153    0.0981063     0.101412   0.120432   0.112312\n",
       " 0.0997213  0.0874415  0.0898499     0.0899084  0.101789   0.103025\n",
       " 0.0956289  0.112312   0.0975442     0.102637   0.0951563  0.0997172\n",
       " 0.0953677  0.0905564  0.103445      0.0951945  0.0955397  0.0973922\n",
       " 0.0946034  0.105409   0.101924   …  0.102384   0.0967843  0.0958434\n",
       " 0.0810437  0.0688525  0.0890232     0.076106   0.080224   0.085484\n",
       " 0.0951543  0.101119   0.101852      0.102188   0.102854   0.0998857\n",
       " 0.102577   0.107872   0.101005      0.110219   0.0991334  0.0995049\n",
       " 0.0870795  0.0961154  0.103722      0.0995175  0.0936292  0.0972707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(train_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loss(model, x, y, device = device)\n",
    "    x = x |>cpu\n",
    "    x_aug = x .+ 0.1f0*randn(eltype(x), size(x)) |> device\n",
    "    y_hat = model(x_aug)\n",
    "    return Flux.crossentropy(y_hat, y) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.007030 seconds (9.03 M allocations: 462.518 MiB, 0.99% gc time, 83.44% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(model, test_set[1],test_set[2])\n",
    "accuracy(model,x, y) = mean(Flux.onecold(model(x)) .== Flux.onecold(y))\n",
    "@time accuracy(model,test_set[1],test_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterSchedulers.Stateful{Exp{Float64}, Int64, ParameterSchedulers.var\"#15#17\"}(Exp{Float64}(0.0001, 0.1), 1, ParameterSchedulers.var\"#15#17\"())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = Flux.Adam(0.001)\n",
    "opt_state = Flux.setup(opt, model);\n",
    "lr_schedule = ParameterSchedulers.Stateful(Exp(start = opt.eta/10, decay = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:1\n",
      "┌ Info: [1]: Test accuracy: 0.8540\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [2]: Test accuracy: 0.8665\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [3]: Test accuracy: 0.8734\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [4]: Test accuracy: 0.8785\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [5]: Test accuracy: 0.8859\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [6]: Test accuracy: 0.8923\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [7]: Test accuracy: 0.8936\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [8]: Test accuracy: 0.8942\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [9]: Test accuracy: 0.8947\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [10]: Test accuracy: 0.8980\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [11]: Test accuracy: 0.8944\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [12]: Test accuracy: 0.8961\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [13]: Test accuracy: 0.8955\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [14]: Test accuracy: 0.8961\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [15]: Test accuracy: 0.8952\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [16]: Test accuracy: 0.8974\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [17]: Test accuracy: 0.8970\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [18]: Test accuracy: 0.8887\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [19]: Test accuracy: 0.8973\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [20]: Test accuracy: 0.8963\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [21]: Test accuracy: 0.8962\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [22]: Test accuracy: 0.8930\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [23]: Test accuracy: 0.8929\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [24]: Test accuracy: 0.8912\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [25]: Test accuracy: 0.8952\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [26]: Test accuracy: 0.8889\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [27]: Test accuracy: 0.8955\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [28]: Test accuracy: 0.9016\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info:  -> New best accuracy! Saving model out to fashionMNIST_conv.bson\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:10\n",
      "┌ Info: [29]: Test accuracy: 0.8965\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [30]: Test accuracy: 0.8904\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [31]: Test accuracy: 0.8908\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [32]: Test accuracy: 0.8887\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [33]: Test accuracy: 0.8965\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [34]: Test accuracy: 0.8940\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [35]: Test accuracy: 0.8960\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [36]: Test accuracy: 0.8947\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [37]: Test accuracy: 0.8936\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [38]: Test accuracy: 0.8937\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-8!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [39]: Test accuracy: 0.8941\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [40]: Test accuracy: 0.8959\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [41]: Test accuracy: 0.8962\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [42]: Test accuracy: 0.8897\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [43]: Test accuracy: 0.8911\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000003e-9!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [44]: Test accuracy: 0.8899\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [45]: Test accuracy: 0.8919\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [46]: Test accuracy: 0.8924\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [47]: Test accuracy: 0.8855\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [48]: Test accuracy: 0.8858\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> Haven't improved in a while, dropping learning rate to 1.0000000000000004e-10!\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:25\n",
      "┌ Info: [49]: Test accuracy: 0.8864\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [50]: Test accuracy: 0.8890\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [51]: Test accuracy: 0.8907\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [52]: Test accuracy: 0.8932\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [53]: Test accuracy: 0.8907\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [54]: Test accuracy: 0.8914\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [55]: Test accuracy: 0.8919\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [56]: Test accuracy: 0.8926\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [57]: Test accuracy: 0.8948\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Info: [58]: Test accuracy: 0.8905\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:8\n",
      "┌ Warning:  -> We're calling this converged.\n",
      "└ @ Main /home/cuongvosgh/Deep_learning/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sdnNjb2RlLXJlbW90ZQ==.jl:30\n"
     ]
    }
   ],
   "source": [
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch = 1:epochs\n",
    "    global best_acc, last_improvement\n",
    "    Flux.train!(loss, model, train_set, opt_state)\n",
    "    acc = accuracy(model,test_set[1],test_set[2])\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch, acc))\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to fashionMNIST_conv.bson\")\n",
    "        ps = cpu(Flux.state(model))\n",
    "        BSON.@save \"fashionMNIST_conv.bson\" ps\n",
    "        jldsave(\"fashionMNIST_conv.jld2\"; ps)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if acc >= 0.95\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 95%\")\n",
    "        break\n",
    "    end\n",
    "    if epoch - last_improvement >= 5 \n",
    "        η = ParameterSchedulers.next!(lr_schedule) \n",
    "        if η ≥ 1e-10\n",
    "            Optimisers.adjust(opt_state, eta = η)\n",
    "            @warn(\" -> Haven't improved in a while, dropping learning rate to $(η)!\")\n",
    "            last_improvement = epoch\n",
    "        end\n",
    "    end\n",
    "    if epoch - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isfile(\"fashionMNIST_conv.bson\") ||\n",
    "download(\"https://github.com/bartoszpankratz/221660-0553-Aproksymacja/blob/master/5.%20Sieci%20konwolucyjne/fashionMNIST_conv.bson?raw=true\")\n",
    "\n",
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 128),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ") |> device\n",
    "\n",
    "BSON.@load \"fashionMNIST_conv.bson\" ps\n",
    "\n",
    "Flux.loadmodel!(model, device(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(model,test_set[1],test_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isfile(\"fashionMNIST_conv.jld2\") ||\n",
    "download(\"https://github.com/bartoszpankratz/221660-0553-Aproksymacja/blob/master/5.%20Sieci%20konwolucyjne/fashionMNIST_conv.jld2?raw=true\")\n",
    "\n",
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 128),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ") |> device\n",
    "\n",
    "\n",
    "ps = JLD2.load(\"fashionMNIST_conv.jld2\", \"ps\")\n",
    "\n",
    "Flux.loadmodel!(model, device(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(model,test_set[1],test_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = Chain(model.layers[1:1]...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
